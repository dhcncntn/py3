import asyncio
import aiohttp
import base64
from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import Command
from aiogram.types import ReplyKeyboardRemove
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.fsm.storage.memory import MemoryStorage

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
BOT_TOKEN = "7267745404:AAEjc5GNhonrXoPSbgRDn8gAGCae0V34wo4"
GEMINI_API_KEY = "AIzaSyBZfx8a3cx9oTLFLcdhceaOqGjwBWGuUDw"
PROXY_URL = "http://grib:work7315@45.140.211.222:50100"
MODEL_NAME = "gemini-1.5-flash"

bot = Bot(token=BOT_TOKEN)
storage = MemoryStorage()
dp = Dispatcher(storage=storage)

user_data = {}
MAX_HISTORY_TOKENS = 8000

class ChatStates(StatesGroup):
    normal = State()
    waiting_for_caption = State()

def estimate_tokens(text):
    return len(text.split()) * 1.5

def trim_history(history):
    total_tokens = 0
    trimmed = []
    for item in reversed(history):
        content = item["parts"][0].get("text", "") if item["parts"] else ""
        total_tokens += estimate_tokens(content)
        trimmed.insert(0, item)
        if total_tokens > MAX_HISTORY_TOKENS:
            trimmed = trimmed[1:]
    return trimmed

async def analyze_image(user_id: int, image_data: bytes = None, caption: str = None):
    if user_id not in user_data:
        user_data[user_id] = {"photos": [], "history": []}

    parts = []
    if image_data:
        prompt = "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"
        if caption:
            prompt += f". –ü–æ–¥–ø–∏—Å—å: {caption}"
        parts.append({"text": prompt})
        parts.append({
            "inline_data": {
                "mime_type": "image/jpeg",
                "data": base64.b64encode(image_data).decode("utf-8")
            }
        })
        user_data[user_id]["photos"].append({"data": image_data, "caption": caption})
    elif caption:
        parts.append({"text": caption})
    else:
        return "‚ùó –ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ –∏–ª–∏ —Ç–µ–∫—Å—Ç."

    user_data[user_id]["history"].append({"role": "user", "parts": parts})
    user_data[user_id]["history"] = trim_history(user_data[user_id]["history"])

    payload = {
        "contents": user_data[user_id]["history"],
        "generationConfig": {
            "maxOutputTokens": 2000,
            "temperature": 0.7
        }
    }

    for attempt in range(3):
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME}:generateContent?key={GEMINI_API_KEY}",
                    json=payload,
                    proxy=PROXY_URL,
                    timeout=aiohttp.ClientTimeout(total=60)
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        response_text = data["candidates"][0]["content"]["parts"][0]["text"]
                        user_data[user_id]["history"].append({"role": "model", "parts": [{"text": response_text}]})
                        return response_text
                    elif response.status == 400:
                        return "‚ö†Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ GPT. –ù–∞–∂–º–∏—Ç–µ /start –¥–ª—è —Å–±—Ä–æ—Å–∞ —Å–µ—Å—Å–∏–∏."
                    elif response.status == 429:
                        if attempt < 2:
                            await asyncio.sleep(2 ** attempt)
                            continue
                        else:
                            return "‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ–¥—Ä—è–¥. –ü–æ–¥–æ–∂–¥–∏ –Ω–µ–º–Ω–æ–≥–æ –∏–ª–∏ –Ω–∞–∂–º–∏ /start –¥–ª—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞."
                    else:
                        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ API (–∫–æ–¥ {response.status}). –ù–∞–∂–º–∏—Ç–µ /start –¥–ª—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞."
        except Exception:
            return "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≤—è–∑–∞—Ç—å—Å—è —Å —Å–µ—Ä–≤–µ—Ä–æ–º. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ /start."

@dp.message(Command("start"))
async def cmd_start(message: types.Message, state: FSMContext):
    user_data[message.from_user.id] = {"photos": [], "history": []}
    await message.answer(
        "ü§ñ <b>–§–æ—Ç–æ–∞–Ω–∞–ª–∏—Ç–∏–∫ Gemini</b>\n"
        "–ü—Ä–∏—Å—ã–ª–∞–π—Ç–µ —Ñ–æ—Ç–æ –∏–ª–∏ —Ç–µ–∫—Å—Ç ‚Äî —è –≤—Å—ë –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é!\n\n"
        "–ö–æ–º–∞–Ω–¥—ã:\n/start ‚Äî –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫\n/help ‚Äî –ø–æ–º–æ—â—å\n/clear ‚Äî –æ—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏",
        reply_markup=ReplyKeyboardRemove(),
        parse_mode="HTML"
    )
    await state.set_state(ChatStates.normal)

@dp.message(Command("help"))
async def cmd_help(message: types.Message):
    help_text = (
        "üì∏ <b>–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</b>\n"
        "1. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ ‚Äî —è –µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é\n"
        "2. –ú–æ–∂–Ω–æ —Å –ø–æ–¥–ø–∏—Å—å—é –∏–ª–∏ –±–µ–∑\n"
        "3. –ú–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å\n"
        "4. –í–æ–ø—Ä–æ—Å—ã –º–æ–∂–Ω–æ –ø–∏—Å–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω–æ –æ—Ç —Ñ–æ—Ç–æ\n\n"
        "‚öôÔ∏è <b>–ö–æ–º–∞–Ω–¥—ã:</b>\n"
        "/start ‚Äî –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ –±–æ—Ç–∞\n"
        "/clear ‚Äî –æ—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏\n"
        "/help ‚Äî –ø–æ–º–æ—â—å"
    )
    await message.answer(help_text, parse_mode="HTML")

@dp.message(Command("clear"))
async def cmd_clear(message: types.Message, state: FSMContext):
    user_data[message.from_user.id] = {"photos": [], "history": []}
    await message.answer("üßπ –ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞. –ú–æ–∂–Ω–æ –ø—Ä–∏—Å—ã–ª–∞—Ç—å –Ω–æ–≤—ã–µ —Ñ–æ—Ç–æ –∏–ª–∏ —Ç–µ–∫—Å—Ç—ã.")
    await state.set_state(ChatStates.normal)

@dp.message(F.photo, ChatStates.normal)
async def handle_photo(message: types.Message, state: FSMContext):
    photo = message.photo[-1]
    file_info = await bot.get_file(photo.file_id)
    file_url = f"https://api.telegram.org/file/bot{BOT_TOKEN}/{file_info.file_path}"

    async with aiohttp.ClientSession() as session:
        async with session.get(file_url) as response:
            image_data = await response.read()

    user_data[message.from_user.id]["current_photo"] = image_data
    await message.answer("üìù –•–æ—Ç–∏—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–¥–ø–∏—Å—å –∫ —Ñ–æ—Ç–æ? –ù–∞–ø–∏—à–∏—Ç–µ –µ—ë –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –ª—é–±–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞.")
    await state.set_state(ChatStates.waiting_for_caption)

@dp.message(F.text, ChatStates.waiting_for_caption)
async def handle_caption(message: types.Message, state: FSMContext):
    user_id = message.from_user.id
    image_data = user_data[user_id]["current_photo"]
    caption = message.text if message.text.lower() != "–ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å" else None

    await message.answer("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
    response = await analyze_image(user_id, image_data=image_data, caption=caption)
    await message.answer(response)
    await state.set_state(ChatStates.normal)

@dp.message(F.text, ChatStates.normal)
async def handle_text(message: types.Message):
    user_id = message.from_user.id
    text = message.text.strip()

    if not text:
        await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç.")
        return

    await message.answer("üí¨ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ç–µ–∫—Å—Ç...")
    response = await analyze_image(user_id, caption=text)
    await message.answer(response)

async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())

